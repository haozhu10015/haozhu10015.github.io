<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="/css/jemdoc.css" type="text/css" />
<link rel="stylesheet" href="/css/papers.css" type="text/css" />
<title>Inverse Reinforcement Learning in Animal Behavior Characterization</title>
<!-- MathJax -->
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@4/tex-mml-chtml.js"></script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End MathJax -->
</head>
<link rel="icon" href="/img/zhicon.png" type="image/x-icon" />
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Hao Zhu</div>
<div class="menu-item"><a href="../index.html">Home</a></div>
<div class="menu-item"><a href="../biography.html">Biography</a></div>
<div class="menu-item"><a href="../teaching.html">Teaching</a></div>
<div class="menu-category">Research</div>
<div class="menu-item"><a href="../papers.html">Papers</a></div>
<div class="menu-item"><a href="../software.html">Software</a></div>
<div class="menu-category">Classes</div>
<div class="menu-item"><a href="../teaching/pgm.html">1228</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Inverse Reinforcement Learning in Animal Behavior Characterization</h1>
<div id="subtitle">J. Boedecker and H. Zhu
</div>
</div>
<p><i><a href="https://www.bcf.uni-freiburg.de/" target=&ldquo;blank&rdquo;>Bernstein Center Freiburg</a> Staff Retreat</i>, September 2024.
</p>
<ul>
<li><p><a href="../pdf/bcf2024miirl.pdf" target=&ldquo;blank&rdquo;>Slides</a>
</p>
</li>
</ul>
<p>Characterizing goal directed animal behavior has been an interesting topic in neuroscience for decades.
The inverse reinforcement learning methods, which have already been widely applied in autonomous driving, control, robotics, etc., are recently recognized as a useful tool in addressing related behavioral neuroscience questions.
In this talk, we briefly introduce the basic idea of inverse reinforcement learning from the perspective of mathematical optimization, and provide some examples about how this idea can be applied in characterizing animal behavior.</p>
<div id="footer">
<div id="footer-text">
Page generated 2025-12-23 14:30:22 CET, by <a href="https://github.com/wsshin/jemdoc_mathjax" target="blank">jemdoc+MathJax</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
