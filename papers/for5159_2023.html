<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="/css/jemdoc.css" type="text/css" />
<link rel="stylesheet" href="/css/papers.css" type="text/css" />
<title>Inverse Q-learning as a tool to investigate behavior and its neural correlates</title>
<!-- MathJax -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End MathJax -->
</head>
<link rel="icon" href="/img/zhicon.png" type="image/x-icon" />
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Hao Zhu</div>
<div class="menu-item"><a href="../index.html">Home</a></div>
<div class="menu-item"><a href="../biography.html">Biography</a></div>
<div class="menu-category">Research</div>
<div class="menu-item"><a href="../papers.html">Papers</a></div>
<div class="menu-item"><a href="../software.html">Software</a></div>
<div class="menu-category">Teaching</div>
<div class="menu-item"><a href="../teaching/pgm.html">PGM</a></div>
<div class="menu-item"><a href="../teaching/realalys.html">Real&nbsp;Analysis</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Inverse Q-learning as a tool to investigate behavior and its neural correlates</h1>
<div id="subtitle">J. Boedecker and H. Zhu
</div>
</div>
<p>(alphabetical author order)
</p>
<p><i><a href="https://www.for5159.de" target=&ldquo;blank&rdquo;>FOR 5159 'Prefrontal Flexibility&rsquo;</a> Agenda Staff Retreat</i>, September 2023.
</p>
<ul>
<li><p><a href="../pdf/for5159_2023.pdf" target=&ldquo;blank&rdquo;>Slides</a>
</p>
</li>
<li><p><a href="https://colab.research.google.com/drive/1YbHB0V1JQ5e_0T5zIR-nmRwmNOILY6v-?usp=sharing" target=&ldquo;blank&rdquo;>Exercise</a> and <a href="https://colab.research.google.com/drive/1ZNthYIGPGIvc7qKQtqySxxwyRhGYLvT2?usp=sharing" target=&ldquo;blank&rdquo;>Solution</a>
</p>
</li>
</ul>
<p>Understanding goal directed animal behavior has been an widely interested topic in the neuroscience community.
Recently, reinforcement learning and inverse reinforcement learning methods have been recognized as a useful tool for the research of this topic.
In this talk we discuss how these tools can be applied to answer the following questions:
How do we explain goal-directed animal behavior given that we often see objectively nonoptimal behavior, which factors contribute, and what are the animals optimizing for?</p>
<div id="footer">
<div id="footer-text">
Page generated 2025-11-11 18:24:41 CET, by <a href="https://github.com/wsshin/jemdoc_mathjax" target="blank">jemdoc+MathJax</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
